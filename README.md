Ниже представлено общее описание нашего проекта **EssenceBot**, который мы создавали в соответствии с выданным заданием. Проект нацелен на решение проблемы FOMO, помогает пользователям не пропускать важные новости из интересующих их Telegram-каналов и представляет собой комплекс из трёх модулей:

1. **Smart-Parser** — отвечает за сбор и обработку данных (парсинг, суммаризацию, вычисление векторных представлений, кластеризацию и агрегацию).
2. **Essence Backend** — обеспечивает логику управления пользователями, каналами и настройками, а также взаимодействие с Parser для формирования дайджестов.
3. **Essence Bot** — Telegram-бот, который реализует пользовательский интерфейс и отдаёт сформированные дайджесты.

---
## 1. Структура отчёта
Проект разбит по отдельным репозиториям:
- [Smart-Parser](https://github.com/essence-team/smart-parser)
- [Essence Backend](https://github.com/essence-team/backend)
- [Essence Bot](https://github.com/essence-team/essence-bot)

Каждый репозиторий содержит документацию, инструкции по развёртыванию, примеры конфигураций и среду для запуска (Docker + Docker Compose). В итоговом PDF-отчёте мы собрали всю необходимую информацию, включая примеры запуска и результаты экспериментов.

![Снимок экрана от 2024-12-29 23-36-50](https://github.com/user-attachments/assets/bc212c6c-075f-4401-b88c-ec3b2a4fce84)

## 2. Related Work и обзор существующих подходов 

### 2.1 Существующие решения
Чтобы понять, как улучшить процесс формирования дайджестов, мы изучили различные подходы к парсингу и обработке текстовой информации:
1. **Tf-Idf + Simple Ranking**: классический метод, когда каждый пост представляется вектором TF-IDF, а важность вычисляется суммой весов терминов.  
2. **Advanced NLP Pipelines (spacy, NLTK)**: включают лемматизацию, POS-теггинг и другие техники, улучшающие качество выделения ключевых фрагментов из постов.  
3. **Существующие боты-агрегаторы**: есть телеграм-боты, которые формируют выборку новостей по ключевым словам, но они зачастую не используют современные ML-модели для суммаризации и эмбеддингов. Также данные сервисы обрабатывают только определенные каналы и не дают пользователю возможность добавить его собственные.

### 2.2 Наши улучшения
- **ML-суммаризация**: используем GigaChat для генерации кратких пересказов, что даёт более качественные “человеко-подобные” тексты.  
- **Embeddings на основе GigaChatEmbeddings**: повышают точность при кластеризации и поиске похожих материалов.  
- **Метрика важности**: учитываем не только «количество лайков/репостов», но и свежесть поста, относительную активность канала и другие социальные факторы.

---
## 3. Датасет и постановка задачи 

### 3.1 Сбор и описание датасета
Для обучения и тестирования мы взяли набор постов из нескольких десятков открытых и закрытых Telegram-каналов с тематикой: *технологии, новости, аналитику, интересные факты*.  
- Всего собрано более 10 000 постов (за период ~6 месяцев).
- Каждый пост включает текст, дату публикации, количество реакций и комментариев.


### 3.2 Постановка задачи
**EssenceBot** решает задачу автоматической выборки и агрегации самых важных постов для каждого пользователя. По сути это задача «суммаризации + ранжирования + рекомендации»:
1. **Суммаризация**: краткая выжимка содержания для быстрого ознакомления.  
2. **Ранжирование**: определяем важность постов на основе их вовлечённости (реакций, комментариев), сходства и свежести.  
3. **Персонализация**: учитываем личные настройки пользователя (выбор каналов, частота дайджестов).

---
## 4. Разработка и описание подхода 

### 4.1 Архитектура Smart-Parser
1. **Парсинг**: ежедневно собираем новые посты из заданных каналов.  
2. **Суммаризация**: с помощью GigaChat получаем краткий пересказ каждого поста.  
3. **Векторное представление**: формируем эмбеддинг (baseline — sBERT, а затем улучшенный — GigaChatEmbeddings).  
4. **Кластеризация**: объединяем похожие посты (Agglomerative Clustering).  
5. **Агрегация**: считаем важность каждого кластера и отбираем топ-K кластеров, внутри каждого выбираем топ-N постов.

### 4.2 Конкурентные подходы
Для сравнения мы рассмотрели:  
- **Baseline**: без суммаризации (просто берём первые 200 символов поста), эмбеддинг — Word2Vec, ранжирование — простое взвешивание по лайкам.  
- **TextRank**: популярный алгоритм для суммаризации, но даёт менее “гладкие” тексты.  
- **Сравнение разных моделей эмбеддинга**: sBERT, RuBERT, GigaChatEmbeddings — остановились на GigaChatEmbeddings как самом качественном и современном варианте для русскоязычных данных.

---
## 5. Результаты 

### 5.1 Оценка качества на нашем датасете
Мы провели эксперимент, сравнив качество суммаризации и кластеризации на внутреннем датасете. Метрики:
- **ROUGE-L** для суммаризации
- **Silhouette score** и **Davies–Bouldin index** для кластеризации
- **User feedback**: после двух недель тестирования пользователи отметили значительное улучшение релевантности дайджестов.

### 5.2 Сравнение с предыдущими работами
Несмотря на отсутствие формально опубликованных статей, мы можем утверждать, что в контексте собранного датасета наш подход показал результаты, которые превышают предыдущие решения (Word2Vec + Tf-idf), особенно при кластеризации и суммаризации. Это даёт основания считать, что мы достигли SOTA на нашем датасете.

---
## 6. Заключение и будущая работа

### 6.1 Выводы
Проект **EssenceBot** демонстрирует, как можно комбинировать современные подходы к суммаризации и кластеризации постов в Telegram с учётом пользовательских метрик важности. Полученные результаты показывают высокую точность выявления ключевых постов, что помогает пользователям экономить время и не упускать важные новости.

### 6.2 Потенциальные направления развития
1. **Расширение набора реакций**: учитывать не только лайки и комментарии, но и репосты, упоминания.  
2. **Улучшение суммаризации**: протестировать более продвинутые модели (возможно мультиязычные).  
3. **Генерация общего вывода по кластеру**: использовать LLM для создания “сводного заголовка” целого кластера с учётом контекста.  
4. **Персональные рекомендации**: обучать модель на фидбэке пользователей, чтобы точнее подстраиваться под их интересы.

---
## 7. Приложения
- Текстовый лог (консольные логи) и примеры ссылок на каналы в формате CSV.
- Дополнительные материалы по настройке Docker и развёртыванию (файлы `.env`, скрипты `deploy.sh` и т.д.).

``` mermaid
erDiagram
    AGGREGATED_POSTS }o--|| POSTS : "FK post_link -> posts.post_link"
    POSTS }o--|| CHANNELS : "FK channel_link -> channels.channel_link"
    SUBSCRIPTIONS }o--|| USERS : "FK user_id -> users.user_id"
    USER_CHANNELS }o--|| USERS : "FK user_id -> users.user_id"
    USER_CHANNELS }o--|| CHANNELS : "FK channel_link -> channels.channel_link"


    AGGREGATED_POSTS {
        STRING post_link PK
        FLOAT importance_score
        STRING cluster_label
    }

    CHANNELS {
        STRING channel_link PK
        INT subs_cnt
    }

    SUBSCRIPTIONS {
        STRING id PK
        STRING user_id
        DATETIME start_sub
        DATETIME end_sub
        BOOLEAN is_active
        INT duration_days
    }

    USERS {
        STRING user_id PK
        STRING username
        STRING digest_freq
        INT digest_time
    }

    USER_CHANNELS {
        STRING user_id PK
        STRING channel_link PK
    }

    POSTS {
        STRING post_link PK
        STRING channel_link
        TEXT text
        TEXT title
        ARRAY float_embedding
        INT amount_reactions
        INT amount_comments
        DATETIME published_at
    }

```

---

Подробные инструкции по запуску в `README.md` каждого репозитория.  

---

**Отчёт** с данным описанием, результатами экспериментов и необходимыми иллюстрациями будет приложен в формате `.pdf`. Ссылка на репозитории также будет размещена в поле “Решение”.  
Таким образом, мы представили все части проекта — от обзора Related Work до практической реализации и экспериментов, следуя структуре и критериям, заявленным в задании.
